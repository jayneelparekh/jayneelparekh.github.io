<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Jayneel Parekh</title> <meta name="author" content="Jayneel Parekh"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jayneelparekh.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jayneel </span>Parekh</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <p>Full list available on <a href="https://scholar.google.com/citations?user=CF7ncpUAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Google Scholar</a></p> <div class="publications"> <ol class="bibliography"><li> <div class="row" style="width:1021px"> <div class="col-sm-2 abbr"></div> <div id="parekh2023tackling" class="col-sm-8"> <div class="title">Tackling Interpretability in Audio Classification Networks with Non-negative Matrix Factorization</div> <div class="author"> <em>Jayneel Parekh</em>, Sanjeel Parekh, Pavlo Mozharovskyi, Gaël Richard, and Florence d’Alché-Buc</div> <div class="periodical"> <em>Accepted in IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP) (available via early access, preprint on arxiv)</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2305.07132.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>This paper tackles two major problem settings for interpretability of audio processing networks, post-hoc and by-design interpretation. For post-hoc interpretation, we aim to interpret decisions of a network in terms of high-level audio objects that are also listenable for the end-user. This is extended to present an inherently interpretable model with high performance. To this end, we propose a novel interpreter design that incorporates non-negative matrix factorization (NMF). In particular, an interpreter is trained to generate a regularized intermediate embedding from hidden layers of a target network, learnt as time-activations of a pre-learnt NMF dictionary. Our methodology allows us to generate intuitive audio-based interpretations that explicitly enhance parts of the input signal most relevant for a network’s decision. We demonstrate our method’s applicability on a variety of classification tasks, including multi-label data for real-world audio and music.</p> </div> </div> </div> </li></ol> <ol class="bibliography"><li> <div class="row" style="width:1021px"> <div class="col-sm-2 abbr"></div> <div id="parekh2022listen" class="col-sm-8"> <div class="title">Listen to Interpret: Post-hoc Interpretability for Audio Networks with NMF</div> <div class="author"> <em>Jayneel Parekh</em>, Sanjeel Parekh, Pavlo Mozharovskyi, Florence d’Alché-Buc, and Gaël Richard</div> <div class="periodical"> <em>Advances in Neural Information Processing Systems <b>(NeurIPS)</b></em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2202.11479.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>This paper tackles post-hoc interpretability for audio processing networks. Our goal is to interpret decisions of a trained network in terms of high-level audio objects that are also listenable for the end-user. To this end, we propose a novel interpreter design that incorporates non-negative matrix factorization (NMF). In particular, a regularized interpreter module is trained to take hidden layer representations of the targeted network as input and produce time activations of pre-learnt NMF components as intermediate outputs. Our methodology allows us to generate intuitive audio-based interpretations that explicitly enhance parts of the input signal most relevant for a network’s decision. We demonstrate our method’s applicability on popular benchmarks, including a real-world multi-label classification task.</p> </div> </div> </div> </li></ol> <ol class="bibliography"><li> <div class="row" style="width:1021px"> <div class="col-sm-2 abbr"></div> <div id="parekh2021framework" class="col-sm-8"> <div class="title">A Framework to Learn with Interpretation</div> <div class="author"> <em>Jayneel Parekh</em>, Pavlo Mozharovskyi, and Florence d’Alché-Buc</div> <div class="periodical"> <em>Advances in Neural Information Processing Systems <b>(NeurIPS)</b></em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://proceedings.neurips.cc/paper/2021/file/cbb6a3b884f4f88b3a8e3d44c636cbd8-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>To tackle interpretability in deep learning, we present a novel framework to jointly learn a predictive model and its associated interpretation model. The interpreter provides both local and global interpretability about the predictive model in terms of human-understandable high level attribute functions, with minimal loss of accuracy. This is achieved by a dedicated architecture and well chosen regularization penalties. We seek for a small-size dictionary of high level attribute functions that take as inputs the outputs of selected hidden layers and whose outputs feed a linear classifier. We impose strong conciseness on the activation of attributes with an entropy-based criterion while enforcing fidelity to both inputs and outputs of the predictive model. A detailed pipeline to visualize the learnt features is also developed. Moreover, besides generating interpretable models by design, our approach can be specialized to provide post-hoc interpretations for a pre-trained neural network. We validate our approach against several state-of-the-art methods on multiple datasets and show its efficacy on both kinds of tasks</p> </div> </div> </div> </li></ol> <ol class="bibliography"> <li> <div class="row" style="width:1021px"> <div class="col-sm-2 abbr"></div> <div id="beaudouin2020flexible" class="col-sm-8"> <div class="title">Flexible and context-specific AI explainability: A multidisciplinary approach</div> <div class="author"> Valérie Beaudouin, Isabelle Bloch, David Bounie, Stéphan Clémençon, Florence d’Alché-Buc, James Eagan, Winston Maxwell, Pavlo Mozharovskyi, and <em>Jayneel Parekh</em> </div> <div class="periodical"> <em>arXiv Preprint, shorter version presented at NeHuAI@ECAI</em> 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2003.07703.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The recent enthusiasm for artificial intelligence (AI) is due principally to advances in deep learning. Deep learning methods are remarkably accurate, but also opaque, which limits their potential use in safety-critical applications. To achieve trust and accountability, designers and operators of machine learning algorithms must be able to explain the inner workings, the results and the causes of failures of algorithms to users, regulators, and citizens. The originality of this paper is to combine technical, legal and economic aspects of explainability to develop a framework for defining the ”right” level of explainability in a given context. We propose three logical steps: First, define the main contextual factors, such as who the audience of the explanation is, the operational context, the level of harm that the system could cause, and the legal/regulatory framework. This step will help characterize the operational and legal needs for explanation, and the corresponding social benefits. Second, examine the technical tools available, including post hoc approaches (input perturbation, saliency maps...) and hybrid AI approaches. Third, as function of the first two steps, choose the right levels of global and local explanation outputs, taking into the account the costs involved. We identify seven kinds of costs and emphasize that explanations are socially useful only when total social benefits exceed costs.</p> </div> </div> </div> </li> <li> <div class="row" style="width:1021px"> <div class="col-sm-2 abbr"></div> <div id="parekh2020speech" class="col-sm-8"> <div class="title">Speech-to-Singing Conversion in an Encoder-Decoder Framework</div> <div class="author"> <em>Jayneel Parekh</em>, Preeti Rao, and Yi-Hsuan Yang</div> <div class="periodical"> <em>IEEE International Conference on Acoustics, Speech and Signal Processing <b>(ICASSP)</b></em> 2020 (<b>Oral</b>) </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2002.06595.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://jayneelparekh.github.io/icassp20/" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="abstract hidden"> <p>In this paper our goal is to convert a set of spoken lines into sung ones. Unlike previous signal processing based methods, we take a learning based approach to the problem. This allows us to automatically model various aspects of this transformation, thus overcoming dependence on specific inputs such as high quality singing templates or phoneme-score synchronization information. Specifically, we propose an encoder–decoder framework for our task. Given timefrequency representations of speech and a target melody contour, we learn encodings that enable us to synthesize singing that preserves the linguistic content and timbre of the speaker while adhering to the target melody. We also propose a multi-task learning based objective to improve lyric intelligibility. We present a quantitative and squalitative analysis of our framework.</p> </div> </div> </div> </li> </ol> <ol class="bibliography"><li> <div class="row" style="width:1021px"> <div class="col-sm-2 abbr"></div> <div id="parekh2018deep" class="col-sm-8"> <div class="title">Deep Pairwise Classification and Ranking for Predicting Media Interestingness</div> <div class="author"> <em>Jayneel Parekh</em>, Harshvardhan Tibrewal, and Sanjeel Parekh</div> <div class="periodical"> <em>ACM International Conference on Multimedia Retrieval <b>(ICMR)</b></em> 2018 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.researchgate.net/publication/325705259_Deep_Pairwise_Classification_and_Ranking_for_Predicting_Media_Interestingness" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>With the explosive increase in the consumption of multimediacontent in recent years, the eld of media interestingness analysishas gained a lot of attention. This paper tackles the problem of imageinterestingness in videos and proposes a novel algorithm basedon pairwise-comparisons of frames to rank all frames in a video.Experiments performed on the Predicting Media Interestingnessdataset, arm its eectiveness over existing solutions. In terms ofthe ocial metric i.e. Mean Average Precision at 10, it outperformsthe previous state-of-the-art (to the best of our knowledge) on thisdataset. Additional results on video interestingness substantiatethe exibility and performance reliability of our approach.</p> </div> </div> </div> </li></ol> <ol class="bibliography"><li> <div class="row" style="width:1021px"> <div class="col-sm-2 abbr"></div> <div id="parekh2017iitb" class="col-sm-8"> <div class="title">The IITB Predicting Media Interestingness System for MediaEval 2017.</div> <div class="author"> <em>Jayneel Parekh</em>, Harshvardhan Tibrewal, and Sanjeel Parekh</div> <div class="periodical"> <em>MediaEval Workshop</em> 2017 </div> <div class="links"> </div> </div> </div> </li></ol> <ol class="bibliography"><li> <div class="row" style="width:1021px"> <div class="col-sm-2 abbr"></div> <div id="parekh2016mlpboon" class="col-sm-8"> <div class="title">The MLPBOON Predicting Media Interestingness System for MediaEval 2016.</div> <div class="author"> <em>Jayneel Parekh</em>, and Sanjeel Parekh</div> <div class="periodical"> <em>MediaEval Workshop</em> 2016 </div> <div class="links"> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Jayneel Parekh. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>